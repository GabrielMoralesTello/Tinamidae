{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9916de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1 — Configuración e imports (Entropía espectral H)\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Carpeta con los .wav (una subcarpeta por especie)\n",
    "IN_DIR = \"../data/Tinamidae\"\n",
    "\n",
    "# Archivo de salida\n",
    "OUT_CSV = \"../traits/output_csv/H.csv\"\n",
    "\n",
    "# Audio\n",
    "SR_TARGET = 44100   # Hz\n",
    "EPS = 1e-12\n",
    "\n",
    "# Frames \n",
    "WIN_LENGTH  = 1024\n",
    "HOP_LENGTH  = WIN_LENGTH // 2  # 50% solape\n",
    "\n",
    "# Entropía (antropy.spectral_entropy, método Welch)\n",
    "USE_ANTROPY   = True   # si no está instalada, se usa fallback con SciPy\n",
    "ENT_NORMALIZE = True   # entropía normalizada a [0,1] (Shannon / log(Nbins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2 — Utilidades: I/O, z-score, frames y entropía H sobre PSD-Welch\n",
    "\n",
    "import librosa\n",
    "from scipy.signal import welch\n",
    "\n",
    "def list_wavs(base_dir: str):\n",
    "    base = Path(base_dir)\n",
    "    return sorted([p for p in base.rglob(\"*.wav\") if p.is_file()])\n",
    "\n",
    "def species_from_path(p: Path, base_dir: str):\n",
    "    \"\"\"\n",
    "    Asume estructura: base_dir/especie/archivo.wav\n",
    "    Devuelve el nombre de la carpeta inmediatamente bajo base_dir.\n",
    "    \"\"\"\n",
    "    base = Path(base_dir).resolve()\n",
    "    rel  = p.resolve().relative_to(base)\n",
    "    return rel.parts[0] if len(rel.parts) > 1 else \"UNKNOWN\"\n",
    "\n",
    "def load_mono(fp: Path):\n",
    "    \"\"\"\n",
    "    Carga audio mono a SR_TARGET.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(str(fp), sr=SR_TARGET, mono=True)\n",
    "    return y.astype(np.float64, copy=False), SR_TARGET\n",
    "\n",
    "def zscore_signal(y: np.ndarray, eps: float = EPS):\n",
    "    \"\"\"\n",
    "    Estandariza la señal: (y - media) / sigma.\n",
    "    \"\"\"\n",
    "    if y.size == 0:\n",
    "        return y\n",
    "    mu = float(np.mean(y))\n",
    "    sd = float(np.std(y, ddof=0))\n",
    "    return (y - mu) / (sd + eps)\n",
    "\n",
    "def estimate_frames(n_samples: int, win: int = WIN_LENGTH, hop: int = HOP_LENGTH) -> int:\n",
    "    \"\"\"\n",
    "    Estima el número de frames T dado win y hop.\n",
    "    \"\"\"\n",
    "    if n_samples < win:\n",
    "        return 1\n",
    "    return 1 + (n_samples - win) // hop\n",
    "\n",
    "# Intento de usar antropy; si no está, fallback SciPy\n",
    "try:\n",
    "    from antropy import spectral_entropy as _ant_spectral_entropy\n",
    "    _HAS_ANTROPY = True\n",
    "except Exception:\n",
    "    _HAS_ANTROPY = False\n",
    "\n",
    "def spectral_entropy_welch(y_hat: np.ndarray, sr: int, normalize: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Entropía de Shannon sobre PSD-Welch normalizada (tratada como distribución de probabilidad).\n",
    "\n",
    "    - Si antropy está disponible y USE_ANTROPY=True:\n",
    "        usa antropy.spectral_entropy(y_hat, sf=sr, method=\"welch\", normalize=normalize)\n",
    "    - Si no, hace:\n",
    "        1) Welch para estimar PSD\n",
    "        2) Normaliza PSD para que sume 1\n",
    "        3) H = -sum p * log(p)\n",
    "        4) Si normalize=True, divide por log(N_bins)\n",
    "    \"\"\"\n",
    "    if y_hat.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    if USE_ANTROPY and _HAS_ANTROPY:\n",
    "        H = _ant_spectral_entropy(\n",
    "            y_hat, sf=sr, method=\"welch\", nperseg=2048, normalize=normalize\n",
    "        )\n",
    "        return float(H)\n",
    "\n",
    "    # Fallback: SciPy Welch + Shannon\n",
    "    f, Pxx = welch(\n",
    "        y_hat, fs=sr, nperseg=2048, noverlap=1024,\n",
    "        window=\"hann\", scaling=\"density\"\n",
    "    )\n",
    "    Pxx = np.maximum(Pxx, 0.0)\n",
    "    psum = np.sum(Pxx) + EPS\n",
    "    p = Pxx / psum                     # distribución de prob sobre las frecuencias\n",
    "    H = -np.sum(p * np.log(p + EPS))   # Shannon\n",
    "    if normalize:\n",
    "        H = H / np.log(p.size)\n",
    "    return float(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580903e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3 — Cálculo de H crudo (H_raw) por archivo\n",
    "\n",
    "files = list_wavs(IN_DIR)\n",
    "print(f\" WAVs encontrados: {len(files)}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fp in files:\n",
    "    sp = species_from_path(fp, IN_DIR)\n",
    "    try:\n",
    "        y, sr    = load_mono(fp)                # 44.1 kHz mono\n",
    "        y_hat    = zscore_signal(y)             # señal canónica\n",
    "        H_raw    = spectral_entropy_welch(y_hat, sr, normalize=ENT_NORMALIZE)\n",
    "        T_frames = int(estimate_frames(len(y_hat), WIN_LENGTH, HOP_LENGTH))\n",
    "\n",
    "        rows.append({\n",
    "            \"species\": sp,\n",
    "            \"relpath\": str(fp),\n",
    "            \"sr\": sr,\n",
    "            \"T_frames\": T_frames,\n",
    "            \"H_raw\": H_raw,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Error en {fp}: {e}\")\n",
    "        rows.append({\n",
    "            \"species\": sp,\n",
    "            \"relpath\": str(fp),\n",
    "            \"sr\": np.nan,\n",
    "            \"T_frames\": 0,\n",
    "            \"H_raw\": np.nan,\n",
    "            \"error\": f\"{type(e).__name__}: {e}\"\n",
    "        })\n",
    "\n",
    "df_H_files = pd.DataFrame(rows)\n",
    "print(\"Archivos procesados:\", df_H_files.shape[0])\n",
    "df_H_files.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4 — Ajuste log(T) y residuales: H_hat = H_raw - (a + b*log(T))\n",
    "\n",
    "df_fit = df_H_files.dropna(subset=[\"H_raw\", \"T_frames\"]).copy()\n",
    "df_fit = df_fit[df_fit[\"T_frames\"] > 1].copy()\n",
    "\n",
    "df_fit[\"log_T\"] = np.log(df_fit[\"T_frames\"].astype(float))\n",
    "\n",
    "x = df_fit[\"log_T\"].values\n",
    "y = df_fit[\"H_raw\"].values\n",
    "\n",
    "# Ajuste lineal: H_raw ~ a + b*log(T_frames)\n",
    "b, a = np.polyfit(x, y, 1)  # slope=b, intercept=a\n",
    "\n",
    "print(f\"Coeficientes de corrección (MCO) usando N = {len(x)} audios:\")\n",
    "print(f\"  a (intercepto) = {a:.6f}\")\n",
    "print(f\"  b (pendiente)  = {b:.6f}\")\n",
    "print(\"Referencia previa (dataset completo): a ≈ 0.496105, b ≈ -0.038873\")\n",
    "\n",
    "# Residuales: H_hat\n",
    "df_fit[\"H_hat\"] = df_fit[\"H_raw\"] - (a + b * df_fit[\"log_T\"])\n",
    "\n",
    "print(\"\\nEjemplo de primeras filas con H_raw y H_hat:\")\n",
    "df_fit[[\"species\", \"T_frames\", \"H_raw\", \"H_hat\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5 — Resumen por especie y export de H.csv\n",
    "\n",
    "df_species = (\n",
    "    df_fit\n",
    "    .dropna(subset=[\"H_raw\", \"H_hat\"])\n",
    "    .groupby(\"species\")\n",
    "    .agg(\n",
    "        n_muestras    = (\"relpath\", \"count\"),\n",
    "        T_frames_mean = (\"T_frames\", \"mean\"),\n",
    "        H_raw_mean    = (\"H_raw\", \"mean\"),\n",
    "        H_raw_median  = (\"H_raw\", \"median\"),\n",
    "        H_hat_mean    = (\"H_hat\", \"mean\"),\n",
    "        H_hat_median  = (\"H_hat\", \"median\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"n_muestras\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Especies con datos:\", df_species.shape[0])\n",
    "df_species.head(10)\n",
    "\n",
    "df_species.to_csv(OUT_CSV, index=False)\n",
    "print(f\"[OK] Archivo guardado en: {OUT_CSV}\")\n",
    "\n",
    "print(\"\\nModo entropía:\",\n",
    "      \"Antropy (Welch)\" if (USE_ANTROPY and _HAS_ANTROPY) else \"SciPy Welch (fallback)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNA",
   "language": "python",
   "name": "dna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
