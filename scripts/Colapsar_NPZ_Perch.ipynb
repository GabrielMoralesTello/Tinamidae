{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa426b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: inspección de estructura\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "ROOT = \"../data/Tinamidae_5s_npz\"\n",
    "\n",
    "species_dirs = sorted([d for d in os.listdir(ROOT) if os.path.isdir(os.path.join(ROOT, d))])\n",
    "counts = {sp: len(glob.glob(os.path.join(ROOT, sp, \"*.npz\"))) for sp in species_dirs}\n",
    "\n",
    "print(f\"Especies encontradas: {len(species_dirs)}\")\n",
    "print(\"Ejemplos de conteos (5 spp):\", list(counts.items())[:5])\n",
    "print(\"Rango de archivos por especie:\",\n",
    "      min(counts.values()) if counts else None, \"—\",\n",
    "      int(np.median(list(counts.values()))) if counts else None, \"—\",\n",
    "      max(counts.values()) if counts else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: función para cargar un vector desde un .npz \n",
    "import numpy as np, os, glob\n",
    "\n",
    "def load_vec_from_npz(path):\n",
    "    with np.load(path, allow_pickle=False) as data:\n",
    "        if 'embedding' in data:\n",
    "            arr = data['embedding']\n",
    "        elif 'arr_0' in data:\n",
    "            arr = data['arr_0']\n",
    "        else:\n",
    "            key = list(data.keys())[0]\n",
    "            arr = data[key]\n",
    "    arr = np.asarray(arr).squeeze()\n",
    "    if arr.ndim > 1:\n",
    "        arr = arr.reshape(-1)\n",
    "    return arr\n",
    "\n",
    "# Prueba con un archivo cualquiera\n",
    "if species_dirs:\n",
    "    test_sp = species_dirs[0]\n",
    "    test_file = glob.glob(os.path.join(ROOT, test_sp, \"*.npz\"))[0]\n",
    "    v = load_vec_from_npz(test_file)\n",
    "    print(\"Prueba:\", test_sp, os.path.basename(test_file), \"shape:\", v.shape)\n",
    "    assert v.ndim == 1, \"El embedding debería ser un vector 1D\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa878f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: construir el CSV 46x1280 usando la MEDIANA por especie\n",
    "import os, glob, numpy as np, pandas as pd\n",
    "\n",
    "OUT_DIR = \"../traits\"\n",
    "OUT_CSV = os.path.join(OUT_DIR, \"traits_high-level.csv\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "summary = {}\n",
    "dims_set = set()\n",
    "\n",
    "for sp in species_dirs:\n",
    "    files = sorted(glob.glob(os.path.join(ROOT, sp, \"*.npz\")))\n",
    "    vecs = []\n",
    "    for f in files:\n",
    "        v = load_vec_from_npz(f)\n",
    "        v = np.asarray(v).reshape(-1)      # aplastar por si viene (1,1280) o (1280,1)\n",
    "        vecs.append(v)\n",
    "        dims_set.add(v.shape[0])\n",
    "    if not vecs:\n",
    "        continue\n",
    "    M = np.stack(vecs, axis=0)             # (n_samples, d)\n",
    "    med = np.median(M, axis=0)             # resumen robusto\n",
    "    summary[sp] = med\n",
    "\n",
    "df = pd.DataFrame.from_dict(summary, orient=\"index\")\n",
    "df.index.name = \"species\"\n",
    "\n",
    "# Forzar nombres de columnas e1..e1280 si la dimensión es 1280\n",
    "if df.shape[1] == 1280:\n",
    "    df.columns = [f\"e{i:04d}\" for i in range(1, 1281)]\n",
    "\n",
    "df.to_csv(OUT_CSV, float_format=\"%.6f\")\n",
    "print(\"Guardado:\", OUT_CSV)\n",
    "print(\"Shape del CSV:\", df.shape)\n",
    "print(\"Dimensiones encontradas:\", dims_set)\n",
    "print(df.iloc[:3, :5])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad149de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Selección de 10 muestras por especie (gradiente radial) + 10 CSVs (uno por set)\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR   = \"../traits\"\n",
    "SETS_DIR  = os.path.join(OUT_DIR, \"gradient_sets\")\n",
    "SEL_CSV   = os.path.join(OUT_DIR, \"selected_samples_gradient.csv\")\n",
    "os.makedirs(SETS_DIR, exist_ok=True)\n",
    "\n",
    "N_SETS = 10\n",
    "Q = np.linspace(0.05, 0.95, N_SETS)  # cuantiles (trim) para evitar outliers extremos\n",
    "METRIC = \"cosine\"  # \"cosine\" o \"euclidean\"\n",
    "\n",
    "def l2_normalize(X, axis=1, eps=1e-12):\n",
    "    n = np.linalg.norm(X, axis=axis, keepdims=True)\n",
    "    return X / (n + eps)\n",
    "\n",
    "def distances_to_median(M, med, metric=\"cosine\"):\n",
    "    if metric == \"euclidean\":\n",
    "        return np.linalg.norm(M - med, axis=1)\n",
    "    elif metric == \"cosine\":\n",
    "        M2 = l2_normalize(M, axis=1)\n",
    "        med2 = med / (np.linalg.norm(med) + 1e-12)\n",
    "        return 1.0 - (M2 @ med2)  # 1 - cos(sim)\n",
    "    else:\n",
    "        raise ValueError(\"metric debe ser 'euclidean' o 'cosine'\")\n",
    "\n",
    "# Aquí acumulamos: (a) el “mapa” de qué archivo fue elegido, y (b) los 10 datasets finales\n",
    "meta_rows = []\n",
    "set_vectors = {k: {} for k in range(N_SETS)}  # set_vectors[k][species] = vector\n",
    "\n",
    "# Diagnóstico: ¿alcanzan los archivos por especie para 10 únicos?\n",
    "counts = {sp: len(glob.glob(os.path.join(ROOT, sp, \"*.npz\"))) for sp in species_dirs}\n",
    "min_n = min(counts.values()) if counts else 0\n",
    "if min_n < N_SETS:\n",
    "    print(f\"WARNING: hay especies con menos de {N_SETS} archivos (mínimo={min_n}).\")\n",
    "    print(\"         En esas especies habrá selección con reemplazo (repetidos) para completar sets.\")\n",
    "\n",
    "for sp in species_dirs:\n",
    "    files = sorted(glob.glob(os.path.join(ROOT, sp, \"*.npz\")))\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    vecs = [np.asarray(load_vec_from_npz(f)).reshape(-1) for f in files]\n",
    "    M = np.stack(vecs, axis=0)      # (n, d)\n",
    "    med = np.median(M, axis=0)      #  “centro”\n",
    "\n",
    "    dist = distances_to_median(M, med, metric=METRIC)\n",
    "    targets = np.quantile(dist, Q)\n",
    "\n",
    "    chosen = set()\n",
    "    chosen_idx = []\n",
    "\n",
    "    for k, t in enumerate(targets):\n",
    "        # ordena candidatos por cercanía al target\n",
    "        cand = np.argsort(np.abs(dist - t))\n",
    "        pick = None\n",
    "        for idx in cand:\n",
    "            if idx not in chosen:\n",
    "                pick = int(idx)\n",
    "                break\n",
    "        if pick is None:\n",
    "            # no quedan únicos (n < N_SETS): usar reemplazo\n",
    "            pick = int(cand[0])\n",
    "\n",
    "        chosen.add(pick)\n",
    "        chosen_idx.append(pick)\n",
    "\n",
    "        meta_rows.append({\n",
    "            \"species\": sp,\n",
    "            \"set\": k + 1,\n",
    "            \"quantile\": float(Q[k]),\n",
    "            \"distance\": float(dist[pick]),\n",
    "            \"file\": files[pick]\n",
    "        })\n",
    "        set_vectors[k][sp] = vecs[pick]\n",
    "\n",
    "# Guardar tabla “qué se eligió”\n",
    "pd.DataFrame(meta_rows).to_csv(SEL_CSV, index=False)\n",
    "print(\"Guardado:\", SEL_CSV)\n",
    "\n",
    "# Guardar 10 CSVs (uno por set)\n",
    "for k in range(N_SETS):\n",
    "    dfk = pd.DataFrame.from_dict(set_vectors[k], orient=\"index\")\n",
    "    dfk.index.name = \"species\"\n",
    "    if dfk.shape[1] == 1280:\n",
    "        dfk.columns = [f\"e{i:04d}\" for i in range(1, 1281)]\n",
    "    out_csv = os.path.join(SETS_DIR, f\"traits_high-level_set{k+1:02d}.csv\")\n",
    "    dfk.to_csv(out_csv, float_format=\"%.6f\")\n",
    "    print(\"Guardado:\", out_csv, \"| shape:\", dfk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d13e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNA",
   "language": "python",
   "name": "dna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
